# ğŸ•µï¸ Fake News Detective

A full-stack AI-powered fake news detection system built with React, Node.js, and Python Flask.

## ğŸš€ Project Structure

```
FakeNewsDetection/
â”œâ”€â”€ client/          # React frontend (Port 3002)
â”œâ”€â”€ server/          # Express.js backend (Port 5000)  
â””â”€â”€ services/        # Python Flask ML service (Port 8000)
```

## âœ¨ Features

- **ğŸ“ Advanced Text Analysis** with custom CSS styling and AI confidence scoring
- **ğŸ”— URL Analysis** - Extract and analyze articles from any news website
- **ğŸ“‚ Batch Processing** - Upload and analyze multiple files simultaneously  
- **ğŸ“± Social Media Integration** - Analyze Twitter, Facebook, Instagram, TikTok posts
- **ğŸ›ï¸ Source Credibility Assessment** - Rate news outlets with reliability database
- **ğŸ” Real-time Fact Checking** - Cross-reference with major fact-checking organizations
- **ğŸ¨ Beautiful Tabbed Interface** with gradient backgrounds and smooth animations
- **âš¡ Real-time Analysis** with loading states and comprehensive error handling
- **ğŸš€ Express.js API Server** with multiple analysis endpoints
- **ğŸ¤– Advanced ML Service** with scikit-learn and NLTK on Render
- **ğŸ“Š Confidence Scoring** with visual progress bars and detailed breakdowns
- **ğŸŒ Responsive Design** that works perfectly on all devices
- **ğŸ”’ Production Ready** with live deployment and environment configurations

## ğŸ› ï¸ Technologies Used

### Frontend (React)
- React 19.1.0 with JavaScript
- Custom CSS with advanced animations and gradients
- Tabbed interface for multiple analysis modes
- Axios for API calls with comprehensive error handling
- Responsive design with modern UI components
- File upload support for batch processing

### Backend (Express.js)
- Express.js with CORS support and multiple endpoints
- Environment variable configuration
- Proxy to ML service with fallback responses
- Advanced error handling and logging
- Support for URL analysis, batch processing, and social media
- Production-ready architecture

### ML Service (Python Flask)
- Flask 3.0.0 with CORS enabled and production optimization
- scikit-learn 1.4.2+ for machine learning with latest compatibility
- NLTK for advanced text preprocessing and tokenization
- TF-IDF vectorization with n-gram support
- Logistic Regression model with confidence scoring
- Comprehensive text preprocessing pipeline
- **Live on Render** with Python 3.12+ compatibility

## ğŸš€ Getting Started

### Prerequisites
- Node.js (v14 or higher)
- Python 3.8+
- npm or yarn

### 1. Start the Express Server
```bash
cd server
npm install
npm start
# Server runs on http://localhost:5000
```

### 2. Start the React Client
```bash
cd client
npm install
npm start
# Client runs on http://localhost:3002
```

### 3. Start the ML Service (Optional - for local testing)
```bash
cd services
pip install -r requirements.txt
python app.py
# ML service runs on http://localhost:8000
```

## ğŸŒ Live Application

- **Frontend**: http://localhost:3002
- **Backend API**: http://localhost:5000/api
- **Live ML Service**: https://fakenewsdetection-927d.onrender.com âœ…

## ğŸ¯ **PRODUCTION STATUS: LIVE!**

âœ… **ML Service Deployed**: https://fakenewsdetection-927d.onrender.com
âœ… **Health Check**: `/health` endpoint active  
âœ… **Predictions**: `/predict` endpoint ready
âœ… **NLTK Data**: Downloaded and configured
âœ… **Mock Model**: Trained and loaded

## ğŸ“Š Current Status

âœ… **Fully Operational System:**
- âœ¨ **Multi-Modal Analysis Interface** with tabbed navigation
- ğŸ”— **URL Analysis** with source credibility assessment  
- ğŸ“‚ **Batch Processing** for multiple file analysis
- ğŸ“± **Social Media Integration** with platform detection
- ğŸ›ï¸ **Source Credibility Database** for major news outlets
- ğŸ” **Fact-Checking Integration** with confidence scoring
- ğŸ¨ **Enhanced UI/UX** with beautiful animations and responsive design
- âš¡ **Real-time Analysis** with comprehensive error handling
- ğŸš€ **Live ML Service** deployed on Render (https://fakenewsdetection-927d.onrender.com)
- ğŸ”„ **Full Integration** between frontend, backend, and ML service
- ğŸ“Š **Advanced Visualizations** with confidence bars and color-coded results
- ğŸŒ **Production Deployment** ready with all premium features

## ğŸ¯ **PREMIUM FEATURES NOW LIVE:**
- **Multi-format support**: Text, URLs, Files, Social Media
- **Advanced credibility scoring** with source reputation analysis  
- **Real-time fact-checking** cross-referencing
- **Professional UI** with tabbed interface and animations
- **Comprehensive reporting** with detailed breakdowns
- **Production deployment** on reliable cloud infrastructure

---

**Built with â¤ï¸ for a more informed world**
â””â”€â”€ services/        # Python Flask ML service
```

## ğŸš€ Features

- **Modern React Frontend** with Tailwind CSS styling
- **Express.js API Backend** for handling requests
- **Python ML Service** with scikit-learn for predictions
- **Real-time Analysis** of news content
- **Beautiful UI/UX** with responsive design
- **Mock ML Model** for development (easily replaceable with real model)
- **Ready for Render Deployment** (ML service)

## ğŸ“‹ Prerequisites

- Node.js (v14 or higher)
- npm or yarn
- Python 3.9+
- pip

## ğŸ› ï¸ Local Development Setup

### 1. Clone and Navigate
```bash
git clone <repository-url>
cd FakeNewsDetection
```

### 2. Setup Client (React Frontend)
```bash
cd client
npm install
npm start
```
The React app will run on `http://localhost:3000`

### 3. Setup Server (Express Backend)
```bash
cd server
npm install
npm run dev
```
The API server will run on `http://localhost:5000`

### 4. Setup ML Service (Python Flask)
```bash
cd services
pip install -r requirements.txt
python app.py
```
The ML service will run on `http://localhost:8000`

## ğŸŒ API Endpoints

### Express Server (Port 5000)
- `GET /` - API information and available endpoints
- `GET /api/health` - Health check and status
- `POST /api/predict` - Traditional text analysis
- `POST /api/analyze-url` - URL extraction and analysis âœ¨
- `POST /api/analyze-batch` - Batch file processing âœ¨ 
- `POST /api/analyze-social` - Social media content analysis âœ¨

### ML Service (Port 8000) - **LIVE ON RENDER** ğŸ‰
- `GET /` - Service information and model details
- `GET /health` - Health check with model status
- `POST /predict` - Core ML model prediction with confidence scoring

## ğŸ“± Usage

### ğŸ¯ **Multiple Analysis Modes:**

1. **ğŸ“ Text Analysis**
   - Paste any news article or text content
   - Get instant AI-powered credibility analysis
   - View confidence scores with visual indicators

2. **ğŸ”— URL Analysis** 
   - Paste any news article URL
   - Automatic text extraction and analysis
   - Source credibility assessment included

3. **ğŸ“‚ Batch Processing**
   - Upload multiple text files (.txt, .doc, .docx)
   - Analyze all files simultaneously
   - Get comprehensive batch report

4. **ğŸ“± Social Media Analysis**
   - Paste social media post content or URLs
   - Platform-specific analysis algorithms
   - Real-time fact-checking integration

### ğŸš€ **Getting Started:**

1. **Start all services** (run in separate terminals)
2. **Open browser** to `http://localhost:3002`
3. **Choose your analysis mode** from the tabbed interface
4. **Enter content** in your preferred format
5. **Click analyze** to get comprehensive results
6. **View detailed breakdowns** with confidence scores and credibility ratings

## ğŸš€ Deployment

### Deploy ML Service to Render

1. **Create a new Web Service** on [Render](https://render.com)
2. **Connect your repository**
3. **Set build/deploy settings:**
   - **Environment:** Python 3
   - **Build Command:** `pip install -r requirements.txt`
   - **Start Command:** `gunicorn app:app`
   - **Root Directory:** `services`

4. **Deploy and get your service URL**

### Update Server Configuration

1. **Edit `server/.env`:**
```env
ML_SERVICE_URL=https://your-render-service.onrender.com
```

2. **Deploy server and client** to your preferred hosting platform

## ğŸ”§ Configuration

### Environment Variables

**Server (.env):**
```env
NODE_ENV=development
PORT=5000
ML_SERVICE_URL=http://localhost:8000
```

**Client:**
- Tailwind CSS configuration in `tailwind.config.js`
- API URL configured in components

## ğŸ¨ Frontend Features

- **Responsive Design** - Works on all devices
- **Beautiful UI** - Modern gradient design with Tailwind CSS
- **Real-time Analysis** - Instant feedback
- **Error Handling** - User-friendly error messages
- **Loading States** - Visual feedback during processing
- **Character Counter** - Text validation
- **Results Display** - Clear visualization of predictions

## ğŸ” ML Model

The current implementation includes a **mock ML model** for development:

- **Algorithm:** Logistic Regression with TF-IDF
- **Features:** Text preprocessing, stopword removal, n-grams
- **Training:** Sample data for demonstration
- **Accuracy:** Mock model for testing purposes

### Replacing with Real Model

To use a real trained model:

1. **Train your model** with real fake news dataset
2. **Save the model** using `joblib.dump()`
3. **Replace the mock model** in `services/app.py`
4. **Update preprocessing** if needed

## ğŸ›¡ï¸ Security Features

- **Input validation** on all endpoints
- **CORS configuration** for secure cross-origin requests
- **Error handling** without exposing sensitive information
- **Text preprocessing** to handle malicious input

## ğŸ“Š Model Performance

Current mock model includes:
- **Text preprocessing** with NLTK
- **TF-IDF vectorization** with n-grams
- **Logistic regression** classification
- **Confidence scoring** for predictions

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the ISC License.

## ğŸ”® Future Enhancements

- [ ] Real ML model with large dataset
- [ ] User authentication
- [ ] Historical analysis
- [ ] Batch processing
- [ ] Advanced NLP features
- [ ] Social media integration
- [ ] API rate limiting
- [ ] Caching layer

## ğŸ†˜ Troubleshooting

### Common Issues

1. **CORS errors**: Check server CORS configuration
2. **ML service not responding**: Verify Python dependencies
3. **Build errors**: Check Node.js and npm versions
4. **Tailwind not working**: Verify PostCSS configuration

### Debug Mode

Enable debug mode by setting:
```env
NODE_ENV=development
```

## ğŸ“ Support

For issues and questions:
1. Check the troubleshooting section
2. Review the API documentation
3. Create an issue in the repository

---

**Built with â¤ï¸ for a more informed world**
